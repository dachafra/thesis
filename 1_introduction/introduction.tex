\chapter{Introduction}
\label{chap:intro}

\epigraph{Your impact will be as big as the quality of your pitch to explain the solution}{\textit{Pieter Colpaert}}

Over the last years, a large and constant growth of data have been made available on the Web. These data are uploading in many different formats such as HTML tables, spreadsheets, PDF documents and web services. One of the most important and successful digital infrastructures that allows to governments, public institutions or non-profit organizations to provide a common and unique point where the data can be accessible by key stakeholders (e.g, citizens, developers, private companies, etc.) are the open data portals. For example, at the time of writing, the European Data Portal\footnote{\url{https://www.europeandataportal.eu/catalogue-statistics/Evolution}} aggregates approximately 700K datasets from EU countries in a diversity of domains. In this context, the W3C organism has proposed a set of technologies and recommendations, which are the basis for Semantic Web, Linked Data, or Knowledge Graphs (KG) data models. RDF~\citep{brickley1999resource} has been proposed as a standard format for data interchange on the Web, and RDF Schema~\citep{brickley2014rdf} and OWL ontologies~\citep{mcguinness2004owl} have begun to appear so as to provide shared models in some domains, while SPARQL~\citep{perez2009semantics} is defined as the standard query language for these data models. However, the amount of non-RDF data (e.g., CSV, JSON, XML) that are published in these open data portals continues to dominate the scene, and interoperability issues hinder their (re)use and consumption. 

%RDF y Semantic Web / Knowledge Graphs
Knowledge graphs, as the most relevant exponent of the use of Semantic Web technologies, have gained momentum as a result of the explosion of available data and the demand of expressive formalisms to integrate factual knowledge spread across various data sources~\citep{abs-2003-02320}. The number of hits per day of public knowledge graphs such as DBpedia\footnote{\url{https://wiki.dbpedia.org/blog/keep-using-dbpedia}} and Wikidata\footnote{\url{https://stats.wikimedia.org/}}, as well as the amount of scientific publications referencing these formal models\footnote{\url{https://pubmed.ncbi.nlm.nih.gov/?term=knowledge+graph}}, provide evidence of the spectrum of opportunities that they are bringing into the industrial and scientific landscape. Although these results endorse the success of Semantic Web technologies, also exhort the development of computational tools to scale up knowledge graphs to the astronomical data growth expected for the next years. The definition of robust methodologies able to integrate these data sources across the web is the first step that has to be solved for starting to see the web as an integrated overall database.


%Integraci√≥n de datos basado en ontologias general
Data integration is not a new problem, it was already identified and addressed several decades ago with an emphasis on data in relational databases, but it is exacerbated by the availability of such data on the Web. Different techniques and tools have been used to address this problem~\citep{Lenzerini02,Halevy18}. In our work, we focus on those approaches based on ontologies and the use of Semantic Web technologies, what has been recently called knowledge graph construction (KGC). The basis of these approaches are, previously namely Ontology Based Data Access (OBDA)~\citep{poggi2008linking}, data consumers issue queries over a dataset according to a common unified view (an ontology). The relationship between the ontology and the data sources is usually available in the form of declarative mapping rules. In Ontology Based Data Integration (OBDI)~\citep{poggi2008linking}, these techniques are expanded to address heterogeneous datasets, whose data need to be integrated to provide answers to these queries. In both knowledge graph construction approaches, two different alternatives exist to enable data access: (1) materialized KGC: where data are transformed taking into account the mappings and the ontologies (for example, data is converted into RDF and loaded into a triple store, so that it can be natively queried using SPARQL), and (2) virtual KGC: where the transformation is done on the queries using the mapping rules, which can then be evaluated on the original data sources. 


The construction of knowledge graphs has been traditionally focused on allowing access to relational databases. With the standardization of the semantic web technologies for representing and querying these data models, the efforts are concentrated in how to define the relationships between the input data (source model) and the ontology (target model). From the very begging, declarative rules have been proposed with this aim~\citep{barrasa2004r2o}, but it is not until the standardization of these rules, with the W3C recommendations R2RML~\citep{R2RML} and Direct Mapping~\citep{arenas2013direct}, where the construction of knowledge graphs from relational databases attract attention from a research point of view. For example, engines and approaches such as Ontop~\citep{calvanese2017ontop}, Morph-RDB~\citep{priyatna2014formalisation} and Ultrawrap~\citep{sequeda2013ultrawrap} describe optimizations in the query translation process from SPARQL-to-SQL taking into account R2RML (or equivalent) mapping rules, usually based on the standard transformation between these two query languages proposed in~\citep{chebotko2009semantics}. The standardization of declarative mapping rules for relational databases also produces the appearance of other mapping specifications with the aim of providing coverage to other kinds of data formats and features. A bit after R2RML was recommended, and because of its use in different types of contexts, new needs and requirements arose, especially in relation to supporting other formats beyond relational databases, and this resulted in the creation of many new mapping languages, such as RML \citep{dimou2014rml} (to deal with CSVs, JSON and XML data sources), xR2RML \citep{michel2015translation} (to deal with MongoDB), KR2RML \citep{slepicka2015kr2rml} (to deal with nested data), CSVW\footnote{\url{https://www.w3.org/ns/csvw}} (to describe CSV files on the Web), or D2RML \citep{chortaras2018d2rml} (for XML, JSON and REST/SPARQL endpoints). In addition to declarative languages, non-declarative mapping languages have also been proposed, such as SPARQL-Generate \citep{lefranccois2017sparql}, Helio\footnote{\url{https://helio.linkeddata.es/}},  Tarql\footnote{\url{https://github.com/tarql/tarql}} or Triplify~\citep{auer2009triplify}. Rhe current situation of an knowledge graph construct practitioner is that needs to provide access to a varied set of heterogeneous data sources but there are many different options to select from, and it is difficult to determine which one is better for each situation. Languages are not necessarily interoperable, and many of them come associated with a very specific engine that supports them.

One of the most used mapping languages to construct knowledge graphs from heterogeneous data sources is RML~\citep{dimou2014rml}. There are a good number of materialized KGC engines that have been proposed for parsing RML mapping rules such as CARML\footnote{\url{https://github.com/carml/carml}}, RMLMapper\footnote{\url{https://github.com/semantifyit/RocketRML}} or RocketRML~\citep{csimcsek2019rocketrml}, but they have addressed the problem from an engineering/technological perspective, hence, they usually have scalability and performance issues in complex data integration scenarios. Virtual KGC engines have been also proposed together with RML mappings~\citep{endris2019ontario,mami2019squerall}, proposing query translation techniques for different and heterogeneous data sources, which is known also as data lakes. Their optimizations are mainly focused on the distribution of the SPARQL query exploiting the mapping rules, and they delegate the execution of the queries to external platforms or databases that provide SQL wrappers such as Presto, SPARK or Apache Drill.

To facilitate data exploitation in this context, application developers need to understand the strengths and weaknesses of existing data integration tools. Additionally, tool developers may want to know if their engines cover the requirements of real-use-case scenarios. In both cases the challenge is to develop a evaluation approaches that covers the requirements for constructing knowledge graphs, and to ensure that are extensible and sustainable over time. In general, it is necessary to have an overview of state of the art engines that are tailored to different source formats, accepting as input those mappings that are represented in a variety of declarative languages. Mainly focused on testing performance and scalability, several benchmarks already exist in the state of the art of virtual knowledge graph construction~\citep{bizer2009berlin,lanti2015npd}. BSBM benchmark~\citep{bizer2009berlin} is focused on comparing the performance of SPARQL-to-SQL query translation versus the performance of native RDF Stores, and only considers virtual KGC engines that access relational data stores. The NPD benchmark~\citep{lanti2015npd} specifically analyzes requirements related to relational databases as data source, query sets, mapping rules and query languages. As a result, none of these benchmarks address the requirement of virtual KGC systems over multiple datasets available in heterogeneous formats. The current engines have been evaluated in an ad-hoc manner~\citep{endris2019ontario,mami2019querying} and to the best of our knowledge, no benchmarks have been developed to evaluate these proposals in a systematic manner. In materialization techniques, to the best of our knowledge, not even a systematic analysis of the parameters that can affect the performance of these systems have been proposed. Apart from testing performance and scalability, it is important to define conformance test cases of the mapping languages specifications. They are able to determine which processor or engine is the most suitable for a certain use case, or provide useful information to the developers for fixing possible issues over their KGC engines. Although R2RML and Direct Mapping have their test-cases~\citep{R2RML_test_cases}, no similar work has been proposed for testing the conformance of engines that construct knowledge graphs from heterogeneous data sources using declarative mapping rules.

%Contribuciones de la tesis high level
We distribute the contributions of this thesis in two different parts. The first part is formed by a set of optimizations techniques for enhancing the construction of knowledge graphs (virtual but also materialized) exploiting the information from the mapping rules. More in detail, we first describe a new concept, \textit{mapping translation}, together with its main desirable properties. This idea want to define how mapping rules have to be interoperable among the different specifications and extensions. This concept defines the foundations for the aforementioned optimizations and improvements over knowledge graph construction processes. For materialization techniques, we propose the exploitation of different types of mapping rules to define and implement a set of physical operators to scale-up the construction of knowledge graphs. We also define a pre-processing framework for the efficient execution of functional mappings (mapping rules that contain declarative data transformation functions) formed by a set of data and mapping translation rules. For virtual KGC system, we describe a set of additional steps over the typical virtual knowledge graph construction workflow for the effective application of domain and integrity constraints over tabular data. The aim of the proposal is to enhance the performance of SPARQL-to-SQL approaches when the input sources are tabular data (e.g., CSV or spreadsheet) together with the improvement of query completeness. Finally, we present a virtual KGC engine able to translate declarative mapping rules into programmed wrappers for allowing the access to legacy systems through non-semantic web query interfaces such as GraphQL.

The second part of the thesis contributions cover the gap of systematic and standard evaluation for knowledge graph construction systems over heterogeneous data sources. We propose the GTFS-Madrid-Bench as a way to evaluate the performance and scalability of different virtual KGC engines, including engines able to translating queries over a semantic data lakes but also most mature ones only focused on SPARQL-to-SQL translation techniques. We are able to evaluate multiple and heterogeneous proposals using a benchmarking single point assessing the current status of these engines. Additionally, our proposal introduces several scenarios that aim at measuring the query capabilities, performance and scalability using an open data model from the transport domain, the General Transit Feed System of GTFS, covering most import SPARQL features and generating data at scale with standard techniques already proposed~\citep{lantivig}. Finally, we analyze what are the parameters that can impact in the performance of materialization KGC engine, together with the definition of a set of testbed that include that parameters and a experimental evaluation over two well known RML engines. Additionally, to coverage the lack of test cases in the construction of KG from heterogeneous data sources, we extend the R2RML test cases to take into account other kinds of data formats using RML mapping. We also deploy the corresponding implementation report of that language\footnote{\url{https://rml.io/implementation-report/}}.




\section{Thesis Structure}
\label{sec:thesisstructure}
The remainder of the thesis is organized as follows:
\begin{itemize}
    \item In Chapter \ref{chap:soa} we analyze the current state of the art directly aligned with the topics of this work. Semantic Web and its main standard technologies for the construction of knowledge graphs, using declarative mapping languages and ontology-based data integration systems. We identify the limitations of the current approaches, which conduct the contributions of the presented work.
    \item In Chapter \ref{chap:objectives} we describe the objectives and main contributions of this thesis. Additionally, we present the assumptions, hypothesis and restrictions of the work.
    \item Chapter \ref{chapter:mappig-translation} defines the concept and properties of a new generation of knowledge graph construction systems, based on the idea of support semantic interoperability among the different types of declarative mapping specifications, what we call \textit{mapping translation}. Additionally, it provides a set of use cases where this idea has been already applied, with a special focus on the construction of KG in the statistics domain.
    \item In Chapter \ref{chapter:evaluation} a set of evaluation proposals for KG construction engines is described. First, we identify and evaluate what are the parameters that can affect the behavior of the KGC engines in materialization environments together with a set of representative test-cases and testbeds that help to perform this kind of evaluations. Finally, we present a comprehensive benchmark for virtual knowledge graph access, which considers multiple data formats and different data scales. Several engines from the state of the art are evaluated with this benchmark so as to assess the current status of virtual knowledge graph access. 
    \item Chapter \ref{chapter:virtual} describes two proposals to optimize the construction of virtual knowledge graphs exploiting the concept of mapping translation. We first describe a set of optimization techniques to enhance completeness and performance of virtual knowledge graph access over tabular data. Second, we present a system that translates declarative mapping rules to programmed query endpoints for providing access to heterogeneous data sources.
    \item In Chapter \ref{chapter:construction}, we describe a set of optimizations techniques over knowledge graph materialization approaches to provide scalability to this process. First, we describe a set of physical data structures and operators for enhancing KG construction techniques and then, an approach for the efficient pre-processing of functional mappings, i.e., mappings that include declarative definition of transformation functions.
    \item Finally, Chapter \ref{chap:conc} describes the main conclusions of this thesis and identified the future lines of research in the are of semantic data integration and knowledge graph construction.
\end{itemize}


\section{Dissemination Results}
\label{sec:disresults}

Our work has been disseminated in the following international workshops, conferences and journals:

\begin{itemize}
    \item Our contribution in Chapter \ref{chapter:mappig-translation} has been published in: Oscar Corcho, Freddy Priyatna and \underline{David Chaves-Fraga}: Towards a New Generation of Ontology Based Data Access, Semantic Web Journal 2020: 153-160.
    \item The implementation over a real use case of the ideas proposed in Chapter \ref{chapter:mappig-translation} has been published in: \underline{David Chaves-Fraga}, Freddy Priyatna, Idafen Santana-P√©rez and Oscar Corcho: Virtual Statistics Knowledge Graph Generation from CSV files, in Proceedings of the 6th International Workshop on Semantic Statistics co-located with the 17th International Semantic Web Conference 2018 (ISWC2018). This paper received the \textbf{Best Paper Award} in the workshop.
    \item The first and second contributions to Chapter \ref{chapter:evaluation} have been published in: Pieter Heyvaert, \underline{David Chaves-Fraga}, Freddy Priyatna, Oscar Corcho, Erick Mannens, Ruben Verborgh and Anastasia Dimou: Conformance test cases for the RDF mapping language (RML), Proceedings of 1st Iberoamerican Knowledge Graphs and Semantic Web Conference 2019 (KGSW2019); and in: \underline{David Chaves-Fraga}, Kemele M. Endris, Enrique Iglesias, Oscar Corcho and Maria-Esther Vidal: What are the Parameters that Affect the Construction of a Knowledge Graph?. In OTM Confederated International Conferences On the Move to Meaningful Internet Systems 2019 (OTM2019). These contributions are the results of joint collaborations with Ghent University and German National Library of Science and Technology (TIB), respectively, as a results of research stays in these institutions and further collaboration work in the context of the W3C\footnote{\url{https://www.w3.org/community/kg-construct/}}.
    \item The last contribution of Chapter \ref{chapter:evaluation} has been published in: \underline{David Chaves-Fraga}, Freddy Priyatna, Andrea Cimmino, Jhon Toledo, Edna Ruckhaus and Oscar Corcho: GTFS-Madrid-Bench: A benchmark for Virtual Knowledge Graph Access in the Transport Domain. Journal of Web Semantics 2020, 65: 100596. 2020\footnote{\url{https://doi.org/10.1016/j.websem.2020.100596}}.
    \item The first part of our contribution to Chapter \ref{chapter:virtual} has been published in: \underline{David Chaves-Fraga}, Edna Ruckhaus, Freddy Priyatna, Maria-Esther Vidal and Oscar Corcho: Enhancing Virtual Ontology Based Access over Tabular Data with Morph-CSV, Semantic Web Journal, 2021.
    \item The second part of our contribution to Chapter \ref{chapter:virtual} has been published in:  Freddy Priyatna, \underline{David Chaves-Fraga}, Ahmad Alobaid, and Oscar Corcho: morph-GraphQL: GraphQL Servers Generation from R2RML Mappings, Proceedings of the 31st International Conference on Software Engineering \& Knowledge Engineering (SEKE2019). The extended version of this research, presented in this thesis, has been published in: \underline{David Chaves-Fraga}, Freddy Priyatna, Ahmad Alobaid and Oscar Corcho: Exploiting Declarative Mapping Rules for Generating GraphQL Servers with Morph-GraphQL. International Journal of Software Engineering and Knowledge Engineering, 2020: 785-803.
    \item The first contribution to Chapter \ref{chapter:construction} has been published in: Enrique Iglesias, Samaneh Jozashoori, \underline{David Chaves-Fraga}, Diego Collarana, and Maria-Esther Vidal: SDM-RDFizer: An RML interpreter for the efficient creation of RDF knowledge graphs, Proceedings of the 29th ACM International Conference on Information and Knowledge Management 2020 (CIKM2020). These contribution is the results of joint collaborations with the German National Library of Science and Technology (TIB), as a results of research stay in the institution and the first three authors have contributed equally to the research.
    \item The second part of our contribution to Chapter \ref{chapter:construction} has been published in: Samaneh Jozashoori, \underline{David Chaves-Fraga}, Enrique Iglesias, Maria-Esther Vidal and Oscar Corcho: FunMap: Efficient Execution of Functional Mappings for Knowledge Graph Creation, Proceedings of the 19th International Semantic Web Conference 2020 (ISWC2020). These contribution is the results of joint collaborations with the German National Library of Science and Technology (TIB), as a results of research stay in the institution and the first two authors have contributed equally to the research.
    
\end{itemize}



