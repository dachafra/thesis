\chapter{Introduction}
\label{chap:intro}

\epigraph{Your impact will be as big as the quality of your pitch to explain the solution}{\textit{Pieter Colpaert}}

Over the last years, a large and constant growth of data have been made available on the Web. These data are published in many different formats such as HTML tables, tabular formats, JSON, PDF documents and web services. Open data portals are one of the most important and successful digital infrastructures that allows governments, public institutions and non-profit organizations to provide a common and unique point where data can be accessible by key stakeholders (e.g, citizens, developers, private companies, etc.). For example, at the time of writing, the European Data Portal\footnote{\url{https://www.europeandataportal.eu/catalogue-statistics/Evolution}} aggregates approximately 1,2M datasets from EU countries in a diversity of domains. In this context, the World Wide Web Consortium (W3C) organism has proposed a set of technologies and recommendations which are the basis for Semantic Web, Linked Data, or Knowledge Graphs (KG) data models. RDF~\citep{brickley1999resource} has been proposed as a standard format for data interchange on the Web, and RDF Schema~\citep{brickley2014rdf} and OWL ontologies~\citep{mcguinness2004owl} have begun to appear so as to provide shared models in some domains, while SPARQL~\citep{perez2009semantics} is defined as the standard query language for these data models. However, the amount of non-RDF data (e.g., CSV, JSON, XML) that are published in these open data portals continues to dominate the scene, and interoperability issues hinder their (re)use and consumption. 

%RDF y Semantic Web / Knowledge Graphs
Knowledge graphs, as the most relevant exponent of the use of Semantic Web technologies, have gained momentum as a result of this explosion of available data and the demand of expressive formalisms to integrate factual knowledge spread across various data sources~\citep{abs-2003-02320}. The number of hits per day of public knowledge graphs such as DBpedia\footnote{\url{https://wiki.dbpedia.org/blog/keep-using-dbpedia}} and Wikidata\footnote{\url{https://stats.wikimedia.org/}}, as well as the amount of increasing scientific publications referencing these formal models\footnote{\url{https://pubmed.ncbi.nlm.nih.gov/?term=knowledge+graph}}, provide evidence of the spectrum of opportunities that they are bringing into the industrial, public administration and scientific landscape. Although these results endorse the success of Semantic Web technologies, they also exhort the development of computational tools to scale up knowledge graphs to the astronomical data growth expected for the next years. The definition of robust methodologies able to integrate these data sources across the Web is the first step that has to be solved for starting to see the Web as an integrated overall database.


%Integraci√≥n de datos basado en ontologias general
Data integration is not a new problem. It was already identified and addressed several decades ago with an emphasis on data stored in relational databases~\citep{wiederhold1992mediators}, but it is exacerbated by the availability of such an amount of heterogeneous data on the Web. Different techniques and tools have been used to address this problem~\citep{gruser1998wrapper,Lenzerini02,Halevy18}. In our work, we focus on approaches based on the use of ontologies as global common modes, and Semantic Web technologies, what has been traditionally named as Ontology-Based Data Access~\citep{poggi2008linking} and more recently as knowledge graph construction (KGC). Data consumers issue queries over a dataset according to a common unified view (an ontology). The relationship between the ontology and the data sources is usually available in the form of declarative mapping rules. In Ontology Based Data Integration (OBDI)~\citep{poggi2008linking}, these techniques are expanded to address heterogeneous datasets, whose data need to be integrated to provide answers to these queries. In knowledge graph construction approaches, two different alternatives have traditionally existed to enable data access: (1) materialized KGC: where data are transformed taking into account the mappings and the ontologies (for example, data is converted into RDF and loaded into a triple store, so that it can be natively queried using SPARQL), and (2) virtual KGC: where the transformation is done on the queries using the mapping rules and ontologies, which can then be evaluated on the original data sources. 


OBDA/I approaches have been traditionally focused on providing access to data stored in relational databases. With the emergence of the Web and the possibility of publishing data in diverse formats, the focus is also expanded to other data publication formats, as aforementioned. Efforts in the last two decades have focused in how to define the relationships between the input data (source model) and the ontology (target model). From the very beginning, declarative rules have been proposed with this aim~\citep{barrasa2004r2o,bizer2004d2rq,auer2009triplify}, but it is not until the standardization of these rules, with the W3C recommendations R2RML~\citep{R2RML} and Direct Mapping~\citep{arenas2013direct}, when the construction of knowledge graphs from relational databases attracted wider attention from a research point of view. For example, engines and approaches such as Ontop~\citep{calvanese2017ontop}, Morph-RDB~\citep{priyatna2014formalisation} and Ultrawrap~\citep{sequeda2013ultrawrap} describe optimizations in the query translation process from SPARQL-to-SQL taking into account R2RML (or equivalent) mapping rules, usually based on the standard transformation between these two query languages proposed in~\citep{chebotko2009semantics, elliott2009complete}. The standardization of declarative mapping rules for relational databases also produces the appearance of other mapping specifications with the aim of providing coverage to other kinds of data formats and features. A bit after R2RML was recommended, and because of its use in different types of contexts, new needs and requirements arose, especially in relation to supporting other formats beyond relational databases, and this resulted in the creation of many new mapping languages, such as RML \citep{dimou2014rml} (to deal with CSVs, JSON and XML data sources), xR2RML \citep{michel2015translation} and  KR2RML \citep{slepicka2015kr2rml} (to deal with nested data), CSVW\footnote{\url{https://www.w3.org/ns/csvw}} (to describe CSV files on the Web), or D2RML \citep{chortaras2018d2rml} (for XML, JSON and REST/SPARQL endpoints). In addition to declarative languages, non-declarative mapping languages have also been proposed, such as SPARQL-Generate \citep{lefranccois2017sparql}, Helio\footnote{\url{https://helio.linkeddata.es/}} or  Tarql\footnote{\url{https://github.com/tarql/tarql}}. A common situation for those performing the construction of a KG is that they need to provide access to a varied set of heterogeneous data sources, but there are so many different options that it is difficult to determine which one is better for each situation. \textbf{Mapping languages are not necessarily interoperable, and many of them come associated with a very specific engine that supports them}.

One of the most used mapping languages to construct knowledge graphs from heterogeneous data sources is RML~\citep{dimou2014rml}. There are a good number of materialized KGC engines that have been proposed for parsing RML mapping rules such as CARML\footnote{\url{https://github.com/carml/carml}}, RMLMapper\footnote{\url{https://github.com/semantifyit/RocketRML}} or RocketRML~\citep{csimcsek2019rocketrml}, but \textbf{no one has addressed in depth typical problems that appear in this context, such as scalability and performance in complex data integration scenarios}. RML-based virtual KGC engines have been also proposed~\citep{endris2019ontario,mami2019squerall}, applying query translation techniques for different and heterogeneous data sources. \textbf{The proposed optimizations by the latest virtual KGC engines are mainly focused on the distribution of the SPARQL queries exploiting the mapping rules}, and they delegate the execution of the queries to external platforms or databases that provide SQL wrappers such as Presto~\citep{bershad1988presto}, SPARK\footnote{\url{https://spark.apache.org/}} or Apache Drill~\citep{hausenblas2013apache}.

In this context, application developers need to understand the strengths and weaknesses of existing KGC engines, so as to determinate whether these engines cover the requirements of real-use-case scenarios. Evaluation approaches are needed to have a clear and up-to-date overview of these engines. Indeed, several benchmarks focused on testing performance and scalability already exist in the state of the art of virtual knowledge graph construction~\citep{bizer2009berlin,lanti2015npd}. The BSBM benchmark~\citep{bizer2009berlin} is focused on comparing the performance of SPARQL-to-SQL query translation versus the performance of native RDF Stores, and only considers virtual KGC engines that access relational data stores. The NPD benchmark~\citep{lanti2015npd} specifically analyzes requirements related to relational databases such as the data source, query sets, mapping rules and query languages. However, \textbf{none of these benchmarks address the requirements of virtual KGC systems over multiple datasets available in heterogeneous formats}. The most recent engines have been evaluated in an ad-hoc manner~\citep{endris2019ontario,mami2019querying} and to the best of our knowledge, no benchmarks have been developed to evaluate these proposals in a systematic manner. In materialization techniques, to the best of our knowledge, not even a systematic analysis of the parameters that can affect the performance of these systems has been proposed. Apart from testing performance and scalability, it is important to define conformance test cases of the mapping language specifications. They are able to determine which processor or engine is the most suitable for a certain use case, or provide useful information to the developers for fixing possible issues over their KGC engines. R2RML and Direct Mapping have their test-cases~\citep{R2RML_test_cases}. However, \textbf{no similar work has been proposed for testing the conformance of engines that construct knowledge graphs from heterogeneous data sources using declarative mapping rules}.

%Contribuciones de la tesis high level
We organize the contributions of this thesis in two different groups. The first group is formed by a set of optimizations techniques for enhancing the construction of knowledge graphs (virtual and materialized) exploiting the information from mapping rules. We first describe the concept of \textit{mapping translation}, together with its main desirable properties. \textit{Mapping translation} describes how mapping rules can be interoperable among the different specifications and extensions. This concept defines the foundations for our proposed optimizations and improvements over knowledge graph construction processes. For materialization techniques, we propose the exploitation of different types of mapping rules to define and implement a set of physical operators to scale-up the construction of knowledge graphs. We also define a pre-processing framework for the efficient execution of functional mappings (mapping rules that contain declarative data transformation functions) formed by a set of data and mapping translation rules. For virtual KGC systems, we describe a set of additional steps over the typical virtual knowledge graph construction workflow for the effective application of domain and integrity constraints over tabular data. The aim of the proposal is to enhance the performance of SPARQL-to-SQL approaches when the input sources are tabular data (e.g., CSV or spreadsheet) together with the improvement of query completeness. Finally, we present a virtual KGC engine able to translate declarative mapping rules into programmed wrappers, for allowing the access to legacy systems through non-semantic web query interfaces such as GraphQL.

The second group of thesis contributions cover the gap of systematic and standard evaluation for knowledge graph construction systems over heterogeneous data sources. We propose the GTFS-Madrid-Bench as a way to evaluate the performance and scalability of different virtual KGC engines, including recent engines able to translate queries over semantic data lakes as most mature engines only focused on SPARQL-to-SQL translation techniques. We are able to evaluate multiple and heterogeneous approaches using the proposed benchmark, assessing the current status of these engines. Additionally, our proposal introduces several scenarios that aim at measuring the query capabilities, performance and scalability using an open data model from the transport domain, the General Transit Feed System of GTFS, covering the most important SPARQL features and generating data at scales with state-of-the-art techniques~\citep{lantivig}. Finally, we analyze what are the parameters that can impact the performance of materialization KGC engines, together with the definition of a set of testbeds that include these parameters and an experimental evaluation over two well known RML engines. Additionally, to cover the lack of test cases in the construction of KG from heterogeneous data sources, we extend the R2RML test cases to take into account other kinds of data formats using RML mappings. We also include the corresponding implementation report of that language\footnote{\url{https://rml.io/implementation-report/}}.




\section{Thesis Structure}
\label{sec:thesisstructure}
The remainder of the thesis is organized as follows:
\begin{itemize}
    \item In Chapter \ref{chap:soa} we analyze the current state of the art directly aligned with the topics of this work. Semantic Web and its main standard technologies for the construction of knowledge graphs, using declarative mapping languages and ontology-based data integration systems. We identify the limitations of the current approaches, which conduct the contributions of the presented work.
    \item In Chapter \ref{chap:objectives} we describe the objectives and main contributions of this thesis. Additionally, we present the assumptions, hypothesis and restrictions of the work.
    \item Chapter \ref{chapter:mappig-translation} defines the concept and properties of a new generation of knowledge graph construction systems, based on the idea of supporting semantic interoperability among the different types of declarative mapping specifications, what we call \textit{mapping translation}. Additionally, it provides a set of use cases where this idea has been already applied, with a special focus on the construction of KG in the statistics domain.
    \item In Chapter \ref{chapter:evaluation} a set of evaluation proposals for KG construction engines is described. First, we identify and evaluate what are the parameters that can affect the behavior of KGC engines in materialization environments together with a set of representative test-cases and testbeds that help to perform this kind of evaluations. Finally, we present a comprehensive benchmark for virtual knowledge graph access, which considers multiple data formats and different data scales. Several engines from the state of the art are evaluated with this benchmark so as to assess the current status of virtual knowledge graph access. 
    \item Chapter \ref{chapter:virtual} describes two proposals to optimize the construction of virtual knowledge graphs exploiting the concept of mapping translation. We first describe a set of optimization techniques to enhance completeness and performance of virtual knowledge graph access over tabular data. Second, we present a system that translates declarative mapping rules to programmed query endpoints for providing access to heterogeneous data sources.
    \item In Chapter \ref{chapter:construction}, we describe a set of optimizations techniques over knowledge graph materialization approaches to provide scalability to this process. First, we describe a set of physical data structures and operators for enhancing KG construction techniques and then, an approach for the efficient pre-processing of functional mappings, i.e., mappings that include declarative definitions of transformation functions.
    \item Finally, Chapter \ref{chap:conc} describes the main conclusions of this thesis and identified the future lines of research in the area of semantic data integration and knowledge graph construction.
\end{itemize}


\section{Dissemination Results}
\label{sec:disresults}

Our work has been disseminated in the following international workshops, conferences and journals:

\begin{itemize}
    \item Our contribution in Chapter \ref{chapter:mappig-translation} has been published in: Oscar Corcho, Freddy Priyatna and \underline{David Chaves-Fraga}: Towards a New Generation of Ontology Based Data Access, Semantic Web Journal 2020: 153-160.
    \item The implementation over a real use case of the ideas proposed in Chapter \ref{chapter:mappig-translation} has been published in: \underline{David Chaves-Fraga}, Freddy Priyatna, Idafen Santana-P√©rez and Oscar Corcho: Virtual Statistics Knowledge Graph Generation from CSV files, in Proceedings of the 6th International Workshop on Semantic Statistics co-located with the 17th International Semantic Web Conference 2018 (ISWC2018). This paper received the \textbf{Best Paper Award} in the workshop.
    \item The first and second contributions to Chapter \ref{chapter:evaluation} have been published in: Pieter Heyvaert, \underline{David Chaves-Fraga}, Freddy Priyatna, Oscar Corcho, Erick Mannens, Ruben Verborgh and Anastasia Dimou: Conformance test cases for the RDF mapping language (RML), Proceedings of the 1st Iberoamerican Knowledge Graphs and Semantic Web Conference 2019 (KGSW2019); and in: \underline{David Chaves-Fraga}, Kemele M. Endris, Enrique Iglesias, Oscar Corcho and Maria-Esther Vidal: What are the Parameters that Affect the Construction of a Knowledge Graph?. In OTM Confederated International Conferences On the Move to Meaningful Internet Systems 2019 (OTM2019). These contributions are the results of joint collaborations with Ghent University and German National Library of Science and Technology (TIB), respectively, as a result of research stays in these institutions and further collaboration work in the context of the W3C\footnote{\url{https://www.w3.org/community/kg-construct/}}.
    \item The last contribution of Chapter \ref{chapter:evaluation} has been published in: \underline{David Chaves-Fraga}, Freddy Priyatna, Andrea Cimmino, Jhon Toledo, Edna Ruckhaus and Oscar Corcho: GTFS-Madrid-Bench: A benchmark for Virtual Knowledge Graph Access in the Transport Domain. Journal of Web Semantics 2020, 65: 100596. 2020\footnote{\url{https://doi.org/10.1016/j.websem.2020.100596}}. Following Open Science principles all code, datasets and queries are available, to facilitate reproducibility and further extensions.
    \item The first part of our contribution to Chapter \ref{chapter:virtual} has been published in: \underline{David Chaves-Fraga}, Edna Ruckhaus, Freddy Priyatna, Maria-Esther Vidal and Oscar Corcho: Enhancing Virtual Ontology Based Access over Tabular Data with Morph-CSV, Semantic Web Journal, 2021.
    \item The second part of our contribution to Chapter \ref{chapter:virtual} has been published in:  Freddy Priyatna, \underline{David Chaves-Fraga}, Ahmad Alobaid, and Oscar Corcho: morph-GraphQL: GraphQL Servers Generation from R2RML Mappings, Proceedings of the 31st International Conference on Software Engineering \& Knowledge Engineering (SEKE2019). The extended version of this research, presented in this thesis, has been published in: \underline{David Chaves-Fraga}, Freddy Priyatna, Ahmad Alobaid and Oscar Corcho: Exploiting Declarative Mapping Rules for Generating GraphQL Servers with Morph-GraphQL. International Journal of Software Engineering and Knowledge Engineering, 2020: 785-803.
    \item The first contribution to Chapter \ref{chapter:construction} has been published in: Enrique Iglesias, Samaneh Jozashoori, \underline{David Chaves-Fraga}, Diego Collarana, and Maria-Esther Vidal: SDM-RDFizer: An RML interpreter for the efficient creation of RDF knowledge graphs, Proceedings of the 29th ACM International Conference on Information and Knowledge Management 2020 (CIKM2020). This contribution is the result of joint collaborations with the German National Library of Science and Technology (TIB), as a result of a research stay in the institution. The first three authors have contributed equally to the research.
    \item The second part of our contribution to Chapter \ref{chapter:construction} has been published in: Samaneh Jozashoori, \underline{David Chaves-Fraga}, Enrique Iglesias, Maria-Esther Vidal and Oscar Corcho: FunMap: Efficient Execution of Functional Mappings for Knowledge Graph Creation, Proceedings of the 19th International Semantic Web Conference 2020 (ISWC2020). This contribution is the result of joint collaborations with the German National Library of Science and Technology (TIB), as a result of a research stay in the institution. The first two authors have contributed equally to the research.
    
\end{itemize}



