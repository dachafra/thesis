\chapter{Objectives and Contributions}

\epigraph{As computer scientist the most important part of a research is the what, not the  thow}{\textit{Maria-Esther Vidal}}

\label{chap:objectives}
As discussed in the previous chapters, in our work we focus on the exploitation of declarative mapping rules for the construction of knowledge graphs from heterogeneous data sources. Additionally, in order to provide a proper and objective evaluation of these kind of systems, we propose and design a set of methodologies and benchmarks to address this issue. This chapter presents the objectives of our work and our contributions to the current state of the art. We also enumerate the assumptions considered when we started this work, and describe the most relevant hypothesis and restrictions that delimit the scope of this thesis.

\section{Objectives}
In the context of this thesis we identify two different goals. First, we propose the concept of \textit{mapping translation} and describe its main properties. Exploiting this concept, and, bringing out a new generation of knowledge graph construction systems, we describe two systems that construct a knowledge graph in a virtual manner (\textit{Morph-CSV} and \textit{Morph-GraphQL}) and other two that perform a KG materialization approach (\textit{SDM-RDFizer} and \textit{FunMap}). The second goal of this thesis is to define standard and objective methodologies to evaluate this new generation of systems. We present a benchmark for virtual knowledge graph access systems \textit{GTFS-Madrid-Bench} and two different studies of the current state of knowledge graph materialization approaches.

In order to achieve the first objective of this thesis, we need to tackle the following open research problems:

\begin{itemize}
    \item The current heterogeneity in the number of declarative mapping specifications reduces the benefits of this approach for constructing knowledge graphs. Based on the W3C recommendation R2RML~\citep{R2RML}, and with the aim of providing support to other formats beyond relational databases, many new declarative mapping languages are proposed such as RML~\citep{dimou2014rml}, xR2RML~\citep{michel2015translation}, KR2RML~\citep{slepicka2015kr2rml}, CSVW~\citep{tennison2015model}, or D2RML~\citep{chortaras2018mapping}. Together with each specification their corresponding parsers have to be implemented, limiting their scope or generalizable optimizations, which negatively impacts on the global adoption of these data integration systems in real-world applications of knowledge graphs.

    \item The construction of virtualized knowledge graphs from raw data (e.g., CSV, JSON or XML) has been tackled as an engineering process delegating the management of these data sources to databases such as Apache Drill\footnote{\url{https://drill.apache.org/}} and Spark-SQL\footnote{\url{https://spark.apache.org/sql/}}. These systems allow the generation of a simple relational database layer over the input data sources. However, in order to tackle the advantage of proposed SPARQL-to-SQL optimization techniques~\citep{priyatna2014formalisation,calvanese2017ontop}, a well-formed RDB is required, including its corresponding constraints. Focused on the specific case of tabular data, we propose a framework that exploits and translates mapping rules and metadata annotations to deal with the typical heterogeneity issues for querying these datasets under an OBDA environment. Its main aim is to improve query evaluation performance, as well as query completeness.
   
    \item Multiple types of query interfaces have been proposed to query heterogeneous data on the web. One of the most recent and relevant incorporation is GraphQL~\citep{graphql}. This technology aims to solve problems such as under/over fetching~\citep{bryant2017graphql,vogel2017experiences,mukhiya2019graphql} of other common used methods for publishing data on the web (e.g., subject-guide HTTP APIs). This specification has been included by multiple organizations in their systems as an integrating query layer over multiple data sources, hence, create a bridge between GraphQL and knowledge graph technologies is relevant. We propose a framework that translates declarative mapping rules to programmed GraphQL data wrappers (known as GraphQL resolvers) helping in their creation and ensuring that their model uses common and shared vocabularies.
\end{itemize}

The previous methodological goals have two associated technological goals. The first one is the implementation of the technological support required to create virtual knowledge graphs over tabular data (Morph-CSV). The second one is implemented by Morph-GraphQL, that translates R2RML mapping rules to programmed GraphQL resolvers for accessing legacy relational database instances.

The second goal is focused on proposing evaluations of knowledge graph construction systems to understand what are their main current limits, and it has the following open research problems:
\begin{itemize}
    \item There is currently no way to obtain objective information about the conformance of knowledge graph construction engines with specifications of declarative mapping languages that go beyond relational databases. Based on the main extension of R2RML, RML~\citep{dimou2014rml}, we proposed a set of representative test cases covering other types of data formats such as JSON, CSV and XML.
    \item There is no analysis of the parameters that affect the process of constructing a knowledge graph from heterogeneous data sources. Previous evaluations have only taken into account data size as a relevant parameter~\citep{lefranccois2017sparql,csimcsek2019rocketrml}. We identify the set of parameters, most of them extracted from the mapping rules, that can also affect to the behavior of these engines.
    \item Finally, the current knowledge graph construction benchmarks~\citep{lanti2015npd,bizer2009berlin} that mainly focused on relational databases, are not enough to test the capabilities of the new generation of engines that are able to integrate or run SPARQL queries over data in several formats. A representative benchmark to test the capabilities of these approaches with objective and useful information is defined.
\end{itemize}



\section{Contributions to the State of the Art}
In this work, we aim to provide solutions to the open research problems described in the previous section. Chapter \ref{chapter:mappig-translation} describes the mapping translation concept and its property, while Chapter \ref{chapter:virtual} provides the solutions to enhance virtual knowledge graph access over heterogeneous data exploiting the aforementioned concept. Chapter \ref{chapter:eval1} describe the previous steps to be performed before define a representative benchmark (Chapter \ref{chapter:eval2}) for KGC engines. The contributions for solving the first research problem are:

\begin{enumerate}
    \item[\textbf{C1.1.}] The concept of \textit{Mapping Translation} and its main properties. 
    \item[\textbf{C1.2.}] The formalization and application of constraints extracted from annotations (mappings and metadata) over tabular data to enhance OBDA approaches. 
    \item[\textbf{C1.3.}] The exploitation of standard declarative mapping rules to automate the generation of programmed GraphQL servers. 
\end{enumerate}

With regard to the second objective, this work presents new contributions in the following aspects:
\begin{enumerate}
    \item[\textbf{C2.1.}] Definition of a set of test cases to test the conformance of KG construction engines in RML.
    \item[\textbf{C2.2.}] Identification and experimental evaluation of the parameters that affect the behavior of the KGC engines. 
    \item[\textbf{C2.3.}] A complete and representative benchmark for evaluating KGC engines, based on open data from the transport domain.
\end{enumerate}

\section{Assumptions}
Our work is based on the following set of assumptions:
\begin{enumerate}[label=\textbf{A{\arabic*}}]
    \item Mapping rules and annotations are declarative and follow W3C standards (or their extensions). 
    \item The target schema (ontology) for integrating the source data is available, and is available in OWL.
    \item Mapping rules and metadata annotations are available.
    \item Data are represented in formats that are not RDF.
    \item We do not have to consider data protection nor access restrictions.
    \item The size of datasets is XXXX.
    \item We are considering static datasets and not streams or APIs.
\end{enumerate}

\section{Hypothesis}

\begin{enumerate}[label=\textbf{H{\arabic*}}]
    \item It is possible to translate declarative mappings
    \item Virtualized Knowledge Graphs are improved in terms of completeness and performance over raw data exploiting declarative mapping rules and metadata annotations.
    \item Not only size data is relevant in the evaluation of KG construction engines
    \item A benchmark blablabla is able to stress and provide a full overview of the state of different engines 
\end{enumerate}

\section{Restrictions}

\begin{enumerate}[label=\textbf{R{\arabic*}}]
    \item Data must be located in the same physical place as XXXXX.
    \item We only consider declarative mapping rules following the RML+FnO~\citep{de2017declarative} specification and metadata annotations in CSVW for Morph-CSV and R2RML for Morph-GraphQL.
    \item The source data generated at scale for evaluating KG construction systems do not need cleaning or preparation functions.
\end{enumerate}
