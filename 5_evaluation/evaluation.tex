\chapter{Systematic Evaluation for Knowledge Graph Construction Engines}
\label{chapter:evaluation}
In this chapter, we present the contributions related to the evaluation of knowledge graph construction systems. On the one hand, the evaluation is relevant for application developers who may need to understand the strengths and weaknesses of existing knowledge graph construction tools. On the other hand, tool developers may want to know whether their engines cover the requirements of real use-case scenarios. In general, it is necessary to have an overview of state-of-the-art engines that are tailored to different source formats, accepting as input mappings that are represented in a variety of declarative languages. 

 Section \ref{chapter5:sec-rml} describes a preliminary set of test cases for testing the conformance of RML mapping language over its available processors, Section \ref{chapter5:sec-param} describes and analyzes the impact of several parameters for the evaluation of materialized KGC engines together with the definition of a set of representative testbeds and their evaluation over two compliant RML engines. Finally, Section \ref{chapter5:sec-bench} presents a virtual knowledge graph construction benchmark over the transport domain. Additionally to the benchmark proposal, an experimental evaluation is performed over four different engines from the state of the art. The three contributions of this chapter define a systematic and comprehensive framework that allows the identification of the strengths and weakness of KGC engines.



\input{5_evaluation/rmlcases}
\input{5_evaluation/parameters}
\input{5_evaluation/benchmark}


\section{Conclusions on Evaluating KGC Engines}
In this chapter, we have described an evaluation framework for KGC engines that includes: i) a set of representative test-cases to test the language conformance of the RML mapping language; ii) an in-depth analysis of the variables and configurations that impact on the behavior of two materialization engines; iii) taking into account the analysis made in the previous point, the definition of a complete and comprehensive benchmark for virtual KGC engines. This evaluation framework has been recently used for testing the capabilities and identifying the limitations of materialization KGC engines~\citep{arenas2021knowledge}, demonstrating that our proposal is useful for both (virtual but also materialized) approaches. Figure \ref{fig:eval-framework} summarize the contributions of this chapter and their influence by past contributions and which will be the next steps. Next steps will include the generation of conceptual test-cases that can be then translated to a specific mapping language, a work that is currently being done in the context of the W3C Community Group of Knowledge Graph Construction and, in terms of performance and scalability, the GTFS-Madrid-Bench can be extended to evaluate the impact of the application of data constraints (e.g., transformation functions) in a KGC process.

\begin{figure}
    \centering
    \includegraphics[angle=90,width=0.5\linewidth]{figures/Evaluation Framework.pdf}
    \caption[Evaluation Framework - Past\&Present\&Future]{\textbf{Evaluation Framework - Past\&Present\&Future.} Summarize of the contributions of this chapter and their influence by past contributions and which are going the expected next steps for a include new features in a new version of the evaluation framework.}
    \label{fig:eval-framework}
\end{figure}